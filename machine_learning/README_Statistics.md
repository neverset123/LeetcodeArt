## 相关性
- 信息量：某个事件出现概率的倒数的对数(概率越低，信息量越大)
- 熵：一个系统所有变量信息量的期望(系统不确定性越高，熵越高)
- 联合熵：多个联合变量的熵
- 条件熵：给定一个变量的条件下，系统的熵
- 相对熵：又称为KL散度，表示两个分布对同一变量的差异（作用：用近似且简单的分布代替复杂的分布）
![image info](../docs/img/relative_entropy.PNG)
- 交叉熵：是相对熵的一部分，用来衡量分布差异性(机器学习计算常用)
- 信息增益：衡量一个变量对系统的影响，通过样本获得
![image info](../docs/img/information_gain.PNG)
- 互信息：同一个系统下两个子系统的对应部分的信息量，通过总体获得